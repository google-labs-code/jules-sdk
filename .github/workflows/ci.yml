# .github/workflows/ci.yml
name: CI

on:
  pull_request:
    types: [opened, synchronize, reopened]

# Prevents multiple runs on the same PR from overlapping
concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality-gate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0 # Required to see commit history and changed files

      - name: Setup Bun
        uses: oven-sh/setup-bun@v1
        with:
          bun-version: latest

      # Bun install is fast enough that complex caching of node_modules often adds more overhead than it saves.
      # We'll rely on Bun's speed. If needed, we can cache ~/.bun/install/cache.

      - name: Install dependencies
        run: bun install --frozen-lockfile

      # 1. Get Changed Files for Jules context (PR only - base_ref is empty on push)
      - name: Get Changed Files
        if: github.event_name == 'pull_request'
        id: changed-files
        run: |
          FILES=$(git diff --name-only origin/${{ github.base_ref }}...HEAD | tr '\n' ' ')
          echo "list=$FILES" >> $GITHUB_OUTPUT

      # 2. Quality Checks (Each captures errors into GITHUB_OUTPUT)
      - name: Check Formatting (warning only)
        id: format
        continue-on-error: true
        run: |
          bun run format:check || echo "::warning::Formatting issues detected. Run 'bun run format' locally."

      - name: Type Check
        id: types
        continue-on-error: true
        run: |
          set -o pipefail
          bun run type-check 2>&1 | tee ts_error.txt || {
            echo "log=$(head -n 50 ts_error.txt | base64 -w 0)" >> $GITHUB_OUTPUT
            exit 1
          }

      - name: Run Tests
        id: tests
        continue-on-error: true
        run: |
          set -o pipefail
          bun run test 2>&1 | tee test_log.txt || {
            echo "log=$(tail -n 80 test_log.txt | base64 -w 0)" >> $GITHUB_OUTPUT
            exit 1
          }

      - name: Production Build
        id: build
        continue-on-error: true
        run: |
          set -o pipefail
          bun run build 2>&1 | tee build_log.txt || {
            echo "log=$(tail -n 40 build_log.txt | base64 -w 0)" >> $GITHUB_OUTPUT
            exit 1
          }

      - name: Smoke Test
        id: smoke
        continue-on-error: true
        run: |
          set -o pipefail
          bun run test:smoke 2>&1 | tee smoke_log.txt || {
            echo "log=$(tail -n 40 smoke_log.txt | base64 -w 0)" >> $GITHUB_OUTPUT
            exit 1
          }

      # 3. Verify Attribution (Dynamic Co-authored-by check) - MOVED TO LAST
      - name: Verify Attribution
        if: github.event_name == 'pull_request'
        id: attribution
        continue-on-error: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          PR_BODY: ${{ github.event.pull_request.body }}
          PR_USER_LOGIN: ${{ github.event.pull_request.user.login }}
          PR_USER_ID: ${{ github.event.pull_request.user.id }}
        run: |
          # Use HEAD SHA to check the actual commit, not the merge commit
          export COMMIT_MSG=$(git show -s --format=%B ${{ github.event.pull_request.head.sha }})
          bun scripts/verify-attribution.ts

      # 4. Report Failures to Jules via modjules
      - name: Report Failure to Jules
        if: always() && github.event_name == 'pull_request' && (github.event.pull_request.user.login == 'google-labs-jules' || endsWith(github.event.pull_request.user.login, '[bot]'))
        env:
          JULES_API_KEY: ${{ secrets.JULES_API_KEY }}
          BRANCH_NAME: ${{ github.head_ref }}
          FILES_CHANGED: ${{ steps.changed-files.outputs.list }}
          PR_BODY: ${{ github.event.pull_request.body }}
          PR_USER_LOGIN: ${{ github.event.pull_request.user.login }}
          PR_USER_ID: ${{ github.event.pull_request.user.id }}

          # Pass raw outputs to shell for correct logic handling
          ATTR_LOG: ${{ steps.attribution.outputs.log }}
          TYPE_LOG: ${{ steps.types.outputs.log }}
          TEST_LOG: ${{ steps.tests.outputs.log }}
          BUILD_LOG: ${{ steps.build.outputs.log }}
          SMOKE_LOG: ${{ steps.smoke.outputs.log }}
        run: |
          # Collect ALL failures into a combined report
          ERROR_TYPES=""
          ERROR_LOGS=""

          if [ -n "$TYPE_LOG" ]; then
            ERROR_TYPES="${ERROR_TYPES}TypeScript Error\n"
            ERROR_LOGS="${ERROR_LOGS}--- TypeScript ---\n$(echo "$TYPE_LOG" | base64 -d)\n\n"
          fi

          if [ -n "$TEST_LOG" ]; then
            ERROR_TYPES="${ERROR_TYPES}Test Failure\n"
            ERROR_LOGS="${ERROR_LOGS}--- Tests ---\n$(echo "$TEST_LOG" | base64 -d)\n\n"
          fi

          if [ -n "$BUILD_LOG" ]; then
            ERROR_TYPES="${ERROR_TYPES}Build Failure\n"
            ERROR_LOGS="${ERROR_LOGS}--- Build ---\n$(echo "$BUILD_LOG" | base64 -d)\n\n"
          fi

          if [ -n "$SMOKE_LOG" ]; then
            ERROR_TYPES="${ERROR_TYPES}Smoke Test Failure\n"
            ERROR_LOGS="${ERROR_LOGS}--- Smoke Test ---\n$(echo "$SMOKE_LOG" | base64 -d)\n\n"
          fi

          if [ -n "$ATTR_LOG" ]; then
            ERROR_TYPES="${ERROR_TYPES}Attribution Check\n"
            ERROR_LOGS="${ERROR_LOGS}--- Attribution ---\n$(echo "$ATTR_LOG" | base64 -d)\n\n"
          fi

          # No errors detected
          if [ -z "$ERROR_TYPES" ]; then
            echo "No failures detected. Skipping report."
            exit 0
          fi

          # Export combined errors for the reporting script
          export ERROR_TYPE=$(echo -e "$ERROR_TYPES" | tr '\n' ', ' | sed 's/, $//')
          export ERROR_LOG_B64=$(echo -e "$ERROR_LOGS" | base64 -w 0)

          # Run the reporting script
          bun scripts/ci-report.ts

      - name: Fail Job if Errors
        if: always()
        run: |
          if [ -n "${{ steps.types.outputs.log }}" ] || [ -n "${{ steps.tests.outputs.log }}" ] || [ -n "${{ steps.build.outputs.log }}" ] || [ -n "${{ steps.smoke.outputs.log }}" ] || [ -n "${{ steps.attribution.outputs.log }}" ]; then
            echo "One or more checks failed."
            exit 1
          fi
